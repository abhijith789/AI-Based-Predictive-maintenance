{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f1424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHIJITH\\AppData\\Local\\Temp\\ipykernel_1524\\1325430152.py:37: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"machine_id\", group_keys=False).apply(add_failure_horizon_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed\n",
      "0    432000\n",
      "1        50\n",
      "Name: count, dtype: int64\n",
      "fail_within_24h\n",
      "0    424800\n",
      "1      7250\n",
      "Name: count, dtype: int64\n",
      "Rows after dropping initial warm-up period: 424900\n",
      "Train distribution (raw):\n",
      "fail_within_24h\n",
      "0    334120\n",
      "1      5800\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test distribution (raw):\n",
      "fail_within_24h\n",
      "0    83530\n",
      "1     1450\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced train distribution:\n",
      "fail_within_24h\n",
      "0    29000\n",
      "1     5800\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classification report with threshold=0.20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.990     0.995     83530\n",
      "           1      0.640     1.000     0.781      1450\n",
      "\n",
      "    accuracy                          0.990     84980\n",
      "   macro avg      0.820     0.995     0.888     84980\n",
      "weighted avg      0.994     0.990     0.991     84980\n",
      "\n",
      "Confusion matrix:\n",
      "[[82716   814]\n",
      " [    0  1450]]\n",
      "\n",
      "Saved model to pd_24h_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. LOAD DATA\n",
    "# -----------------------------------\n",
    "df = pd.read_csv(\"synthetic_sensor_data.csv\", parse_dates=[\"timestamp\"])\n",
    "\n",
    "# Ensure correct ordering\n",
    "df = df.sort_values([\"machine_id\", \"timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------------\n",
    "# 2. CREATE TARGET: fail_within_24h\n",
    "# -----------------------------------\n",
    "HORIZON_HOURS = 24\n",
    "\n",
    "def add_failure_horizon_labels(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    group = group.sort_values(\"timestamp\").copy()\n",
    "    \n",
    "    group[\"failure_time\"] = group[\"timestamp\"].where(group[\"failed\"] == 1)\n",
    "    group[\"next_failure_time\"] = group[\"failure_time\"].bfill()\n",
    "    \n",
    "    time_diff = group[\"next_failure_time\"] - group[\"timestamp\"]\n",
    "    group[\"time_to_next_failure_hours\"] = time_diff.dt.total_seconds() / 3600\n",
    "    \n",
    "    group[\"fail_within_24h\"] = (\n",
    "        (group[\"time_to_next_failure_hours\"] >= 0) &\n",
    "        (group[\"time_to_next_failure_hours\"] <= HORIZON_HOURS)\n",
    "    ).astype(int)\n",
    "    \n",
    "    return group\n",
    "\n",
    "df = df.groupby(\"machine_id\", group_keys=False).apply(add_failure_horizon_labels)\n",
    "\n",
    "print(df[\"failed\"].value_counts())\n",
    "print(df[\"fail_within_24h\"].value_counts())\n",
    "\n",
    "# -----------------------------------\n",
    "# 3. FEATURE ENGINEERING (rolling stats)\n",
    "# -----------------------------------\n",
    "# We have data every 10 minutes:\n",
    "FREQ_MIN = 10\n",
    "STEPS_PER_HOUR = int(60 / FREQ_MIN)    # 6\n",
    "WINDOW_6H = 6 * STEPS_PER_HOUR         # 36\n",
    "WINDOW_24H = 24 * STEPS_PER_HOUR       # 144\n",
    "\n",
    "sensor_cols = [\"temp_c\", \"vibration_ms2\", \"pressure_psi\", \"load_pct\", \"rpm\"]\n",
    "\n",
    "df = df.sort_values([\"machine_id\", \"timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "grouped = df.groupby(\"machine_id\", group_keys=False)\n",
    "\n",
    "for col in sensor_cols:\n",
    "    # 6-hour rolling stats\n",
    "    df[f\"{col}_mean_6h\"] = grouped[col].rolling(window=WINDOW_6H, min_periods=WINDOW_6H).mean().reset_index(level=0, drop=True)\n",
    "    df[f\"{col}_std_6h\"]  = grouped[col].rolling(window=WINDOW_6H, min_periods=WINDOW_6H).std().reset_index(level=0, drop=True)\n",
    "    df[f\"{col}_max_6h\"]  = grouped[col].rolling(window=WINDOW_6H, min_periods=WINDOW_6H).max().reset_index(level=0, drop=True)\n",
    "    \n",
    "    # 24-hour rolling stats\n",
    "    df[f\"{col}_mean_24h\"] = grouped[col].rolling(window=WINDOW_24H, min_periods=WINDOW_24H).mean().reset_index(level=0, drop=True)\n",
    "    df[f\"{col}_std_24h\"]  = grouped[col].rolling(window=WINDOW_24H, min_periods=WINDOW_24H).std().reset_index(level=0, drop=True)\n",
    "    \n",
    "    # Trend features (delta from 24h mean)\n",
    "    df[f\"{col}_delta_24h\"] = df[col] - df[f\"{col}_mean_24h\"]\n",
    "\n",
    "# Example spike feature for temperature: count of high-temp points in last 24h\n",
    "df[\"temp_high\"] = (df[\"temp_c\"] > 80).astype(int)\n",
    "df[\"temp_high_count_24h\"] = grouped[\"temp_high\"].rolling(window=WINDOW_24H, min_periods=WINDOW_24H).sum().reset_index(level=0, drop=True)\n",
    "\n",
    "# -----------------------------------\n",
    "# 4. CLEAN UP & DROP EARLY ROWS WITHOUT FULL HISTORY\n",
    "# -----------------------------------\n",
    "# Drop rows where 24h features are NaN (initial warm-up period per machine)\n",
    "feature_cols = [c for c in df.columns if any(k in c for k in [\"mean_6h\", \"std_6h\", \"max_6h\", \"mean_24h\", \"std_24h\", \"delta_24h\", \"temp_high_count_24h\"])]\n",
    "\n",
    "df_model = df.dropna(subset=feature_cols + [\"fail_within_24h\"]).copy()\n",
    "\n",
    "print(\"Rows after dropping initial warm-up period:\", len(df_model))\n",
    "\n",
    "# -----------------------------------\n",
    "# 5. TRAIN-TEST SPLIT (TIME-BASED)\n",
    "# -----------------------------------\n",
    "# We use a stratified split so both train and test contain positives.\n",
    "df_train, df_test = train_test_split(\n",
    "    df_model,\n",
    "    test_size=0.2,\n",
    "    stratify=df_model[\"fail_within_24h\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"Train distribution (raw):\")\n",
    "print(df_train[\"fail_within_24h\"].value_counts())\n",
    "print(\"\\nTest distribution (raw):\")\n",
    "print(df_test[\"fail_within_24h\"].value_counts())\n",
    "\n",
    "# -----------------------------------\n",
    "# 5B. FIX CLASS IMBALANCE (UNDERSAMPLE MAJORITY)\n",
    "# -----------------------------------\n",
    "train_pos = df_train[df_train[\"fail_within_24h\"] == 1]\n",
    "train_neg = df_train[df_train[\"fail_within_24h\"] == 0]\n",
    "\n",
    "# e.g., keep about 5Ã— as many negatives as positives\n",
    "neg_sample_size = min(len(train_neg), len(train_pos) * 5)\n",
    "train_neg_sampled = train_neg.sample(n=neg_sample_size, random_state=42)\n",
    "\n",
    "train_balanced = pd.concat([train_pos, train_neg_sampled], axis=0)\n",
    "train_balanced = train_balanced.sample(frac=1.0, random_state=42)\n",
    "\n",
    "X_train = train_balanced[feature_cols]\n",
    "y_train = train_balanced[\"fail_within_24h\"]\n",
    "\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test[\"fail_within_24h\"]\n",
    "\n",
    "print(\"\\nBalanced train distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# -----------------------------------\n",
    "# 6. TRAIN MODEL (NO class_weight needed now)\n",
    "# -----------------------------------\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------------\n",
    "# 7. EVALUATE WITH CUSTOM THRESHOLD\n",
    "# -----------------------------------\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "THRESHOLD = 0.20\n",
    "y_pred = (y_proba >= THRESHOLD).astype(int)\n",
    "\n",
    "print(\"\\n===================================================\")\n",
    "print(\" Evaluation Metrics (Threshold = 0.20)\")\n",
    "print(\"===================================================\\n\")\n",
    "\n",
    "# Basic metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "# AUC uses raw probabilities\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"Accuracy:      {acc:.4f}\")\n",
    "print(f\"Precision:     {prec:.4f}\")\n",
    "print(f\"Recall:        {rec:.4f}\")\n",
    "print(f\"F1 Score:      {f1:.4f}\")\n",
    "print(f\"ROC AUC Score: {auc:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=3, zero_division=0))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# -----------------------------------\n",
    "# 8. SAVE MODEL FOR API/APP\n",
    "# -----------------------------------\n",
    "model_artifact = {\n",
    "    \"model\": clf,\n",
    "    \"feature_cols\": feature_cols\n",
    "}\n",
    "joblib.dump(model_artifact, \"pd_24h_model.joblib\")\n",
    "print(\"\\nSaved model to pd_24h_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f3f4824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        machine_id           timestamp  fail_within_24h  proba_24h\n",
      "314389          36 2024-01-24 00:10:00                1        1.0\n",
      "97517           11 2024-01-18 03:00:00                1        1.0\n",
      "252641          29 2024-01-15 06:00:00                1        1.0\n",
      "149757          17 2024-01-20 20:40:00                1        1.0\n",
      "211120          24 2024-01-26 22:40:00                1        1.0\n"
     ]
    }
   ],
   "source": [
    "test_with_proba = df_test.copy()\n",
    "test_with_proba[\"proba_24h\"] = y_proba\n",
    "test_with_proba[\"pred_24h\"] = y_pred\n",
    "\n",
    "top_risky = test_with_proba.sort_values(\"proba_24h\", ascending=False).head(5)\n",
    "print(top_risky[[\"machine_id\", \"timestamp\", \"fail_within_24h\", \"proba_24h\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8200a5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"features\": {\n",
      "    \"temp_c_mean_6h\": 53.09034997399457,\n",
      "    \"temp_c_std_6h\": 1.4735653006910328,\n",
      "    \"temp_c_max_6h\": 55.84817091710335,\n",
      "    \"temp_c_mean_24h\": 53.004187741689236,\n",
      "    \"temp_c_std_24h\": 1.4868246891417372,\n",
      "    \"temp_c_delta_24h\": -0.4837839860909128,\n",
      "    \"vibration_ms2_mean_6h\": 1.4155767559021806,\n",
      "    \"vibration_ms2_std_6h\": 0.23188955796635718,\n",
      "    \"vibration_ms2_max_6h\": 1.796030761466754,\n",
      "    \"vibration_ms2_mean_24h\": 1.4065725545192405,\n",
      "    \"vibration_ms2_std_24h\": 0.19728263161063844,\n",
      "    \"vibration_ms2_delta_24h\": -0.4187337158595793,\n",
      "    \"pressure_psi_mean_6h\": 291.4320385316424,\n",
      "    \"pressure_psi_std_6h\": 4.679774079921187,\n",
      "    \"pressure_psi_max_6h\": 307.90479057055666,\n",
      "    \"pressure_psi_mean_24h\": 291.3555304356021,\n",
      "    \"pressure_psi_std_24h\": 5.130662363775696,\n",
      "    \"pressure_psi_delta_24h\": 3.50646884951027,\n",
      "    \"load_pct_mean_6h\": 64.33589257972311,\n",
      "    \"load_pct_std_6h\": 5.248372517165115,\n",
      "    \"load_pct_max_6h\": 77.97957539323222,\n",
      "    \"load_pct_mean_24h\": 64.08843113636408,\n",
      "    \"load_pct_std_24h\": 4.621490202613354,\n",
      "    \"load_pct_delta_24h\": 4.812457527825558,\n",
      "    \"rpm_mean_6h\": 1590.634718289148,\n",
      "    \"rpm_std_6h\": 39.3447494156217,\n",
      "    \"rpm_max_6h\": 1664.089273982737,\n",
      "    \"rpm_mean_24h\": 1597.6278124112464,\n",
      "    \"rpm_std_24h\": 40.05064897900898,\n",
      "    \"rpm_delta_24h\": -78.97284465312168,\n",
      "    \"temp_high_count_24h\": 0.0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "row = top_risky.iloc[0]\n",
    "feature_payload = {col: float(row[col]) for col in feature_cols}\n",
    "print(json.dumps({\"features\": feature_payload}, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
